{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ogatash-lab/ARES2023ExpData/blob/main/MLR.ipynb)"
      ],
      "metadata": {
        "id": "nUAv5AtK9QPe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries"
      ],
      "metadata": {
        "id": "C2uEt6ECeG3l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "print(sklearn.__version__)\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy.lib.function_base import vectorize\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from numpy.core.fromnumeric import size\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "import tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2iu9jfOyXCG",
        "outputId": "4d8c7baf-1427-4f24-b86c-cbe9c4af1bde"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data-Set"
      ],
      "metadata": {
        "id": "wxFMiYVheYRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_2007 = pd.read_csv(\"https://raw.githubusercontent.com/sho6210/test/main/data/data_set_2007.csv\", header=0)\n",
        "df_2008 = pd.read_csv(\"https://raw.githubusercontent.com/sho6210/test/main/data/data_set_2008.csv\", header=0)\n",
        "df_2009 = pd.read_csv(\"https://raw.githubusercontent.com/sho6210/test/main/data/data_set_2009.csv\", header=0)\n",
        "df_2010 = pd.read_csv(\"https://raw.githubusercontent.com/sho6210/test/main/data/data_set_2010.csv\", header=0)\n",
        "df_2011 = pd.read_csv(\"https://raw.githubusercontent.com/sho6210/test/main/data/data_set_2011.csv\", header=0)\n",
        "df_2012 = pd.read_csv(\"https://raw.githubusercontent.com/sho6210/test/main/data/data_set_2012.csv\", header=0)\n",
        "df_2013 = pd.read_csv(\"https://raw.githubusercontent.com/sho6210/test/main/data/data_set_2013.csv\", header=0)\n",
        "df_2014 = pd.read_csv(\"https://raw.githubusercontent.com/sho6210/test/main/data/data_set_2014.csv\", header=0)\n",
        "df_2015 = pd.read_csv(\"https://raw.githubusercontent.com/sho6210/test/main/data/data_set_2015.csv\", header=0)\n",
        "df_2016 = pd.read_csv(\"https://raw.githubusercontent.com/sho6210/test/main/data/data_set_2016.csv\", header=0)\n",
        "df_2017 = pd.read_csv(\"https://raw.githubusercontent.com/sho6210/test/main/data/data_set_2017.csv\", header=0)\n",
        "df_2018 = pd.read_csv(\"https://raw.githubusercontent.com/sho6210/test/main/data/data_set_2018.csv\", header=0)\n",
        "df_2019 = pd.read_csv(\"https://raw.githubusercontent.com/sho6210/test/main/data/data_set_2019.csv\", header=0)\n",
        "\n",
        "# df_0000 storage list\n",
        "list_df = [df_2007, df_2008, df_2009, df_2010, df_2011, df_2012, df_2013, df_2014, df_2015, df_2016, df_2017, df_2018, df_2019]"
      ],
      "metadata": {
        "id": "mi3BWBebeRLv"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading and data splitting"
      ],
      "metadata": {
        "id": "3rmQiwieyvmy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def DataMake(split, metric, list_df):\n",
        "  # variable\n",
        "  label_train = []\n",
        "  label_test = []\n",
        "  sentences_train = []\n",
        "  sentences_test = []\n",
        "\n",
        "  # Split the correct answer labels and target sentences into study and test.\n",
        "  list_train = list_df[:split]\n",
        "  list_test = list_df[split:]\n",
        "  print('metric:', metric)\n",
        "  print('train:', len(list_train), 'test:', len(list_test))\n",
        "\n",
        "  # Store data frames for testing in df_test.\n",
        "  df_test = pd.concat(list_test)\n",
        "\n",
        "  # Extract and list metric value in a list.\n",
        "  for i in list_train:\n",
        "    label_train.append(i[metric].values)\n",
        "    sentences_train.append(i['Description'].values)\n",
        "  for i in list_test:\n",
        "    label_test.append(i[metric].values)\n",
        "    sentences_test.append(i['Description'].values)\n",
        "\n",
        "  # data for input\n",
        "  # metric value\n",
        "  y_train = np.concatenate(label_train, 0)\n",
        "  y_test = np.concatenate(label_test, 0)\n",
        "  # description\n",
        "  train_sentence = np.concatenate(sentences_train, 0)\n",
        "  test_sentence = np.concatenate(sentences_test, 0)\n",
        "\n",
        "  return y_train, y_test, train_sentence, test_sentence, df_test"
      ],
      "metadata": {
        "id": "7EFClJiGyi7y"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Natural Language Processing (train)"
      ],
      "metadata": {
        "id": "YfYxevRwfneG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def NLP_train(train_sentence):\n",
        "  # Natural Language Processing\n",
        "  # Creating BoW features with sklearn's CountVectorizer\n",
        "  vectorizer = CountVectorizer(stop_words=\"english\")\n",
        "  X_train = vectorizer.fit_transform(train_sentence)\n",
        "  \n",
        "  return X_train, vectorizer"
      ],
      "metadata": {
        "id": "UFh_yTKG_L3d"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multinomial Logistic Regression (train)"
      ],
      "metadata": {
        "id": "OhGKDuML0g93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def MLR_train(X_train, y_train):\n",
        "  # Create a classification model for MLR using vectorized features\n",
        "  lr = LogisticRegression(C=0.3, random_state=0, n_jobs=-1)\n",
        "  lr.fit(X_train, y_train)\n",
        "\n",
        "  return lr\n",
        "\n"
      ],
      "metadata": {
        "id": "A-Y15tpr_9jv"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Natural Language Processing (test)"
      ],
      "metadata": {
        "id": "A1MAf62J0tPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def NLP_test(test_sentence, vectorizer):\n",
        "  # Natural Language Processing\n",
        "  # Creating BoW features with sklearn's CountVectorizer.\n",
        "  X_test = vectorizer.transform(test_sentence)\n",
        "  \n",
        "  return X_test"
      ],
      "metadata": {
        "id": "JVv9EtnWlZrm"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multinomial Logistic Regression (test)"
      ],
      "metadata": {
        "id": "2rxS6KVU0vh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def MLR_test(metric, X_test, y_test, lr):\n",
        "  # Test data to confirm accuracy.\n",
        "  y_pred = lr.predict(X_test)\n",
        "  cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "  # Branching when creating a table.\n",
        "  if metric == 'AV':\n",
        "    table = pd.DataFrame(cm, columns=['Predicted P', 'Predicted L', 'Predicted A', 'Predicted N'], index=['Actual P', 'Actual L', 'Actual A', 'Actual N'])\n",
        "  elif metric == 'AC':\n",
        "    table = pd.DataFrame(cm, columns=['Predicted L', 'Predicted H'], index=['Actual L', 'Actual H'])\n",
        "  elif metric == 'PR':\n",
        "    table = pd.DataFrame(cm, columns=['Predicted N', 'Predicted L', 'Predicted H'], index=['Actual N', 'Actual L', 'Actual H'])\n",
        "  elif metric == 'UI':\n",
        "    table = pd.DataFrame(cm, columns=['Predicted N', 'Predicted R'], index=['Actual N', 'Actual R'])\n",
        "  elif metric == 'S':\n",
        "    table = pd.DataFrame(cm, columns=['Predicted U', 'Predicted C'], index=['Actual U', 'Actual C'])\n",
        "  else:\n",
        "    table = pd.DataFrame(cm, columns=['Predicted N', 'Predicted L', 'Predicted H'], index=['Actual N', 'Actual L', 'Actual H'])\n",
        "\n",
        "  # Accuracy\n",
        "  print(\"accuracy:\", accuracy_score(y_test, y_pred))\n",
        "  print(table)\n",
        "  print('-'*70)\n",
        "\n",
        "  # Returns a list containing the prediction results and a data frame for testing.\n",
        "  return y_pred, df_test\n",
        "\n"
      ],
      "metadata": {
        "id": "65tQ7Pvnmg76"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example"
      ],
      "metadata": {
        "id": "dYF-OpMa03Ra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = ['AV', 'AC', 'PR', 'UI', 'S', 'C', 'I', 'A']\n",
        "split = 12\n",
        "\n",
        "for metric in metrics:\n",
        "  y_train, y_test, train_sentence, test_sentence, df_test = DataMake(split, metric, list_df)\n",
        "\n",
        "  X_train, vectorizer = NLP_train(train_sentence)\n",
        "  lr = MLR_train(X_train, y_train)\n",
        "\n",
        "  X_test = NLP_test(test_sentence, vectorizer)\n",
        "  MLR_test(metric, X_test, y_test, lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oB6I7HqcofQ2",
        "outputId": "79390614-dd6c-4ed5-c33c-940ec34ac913"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "metric: AV\n",
            "train: 11 test: 2\n",
            "accuracy: 0.8702647514434587\n",
            "          Predicted P  Predicted L  Predicted A  Predicted N\n",
            "Actual P          103           54          351            1\n",
            "Actual L           17         3919         1752           11\n",
            "Actual A           86         1179        20603            8\n",
            "Actual N            4           71          151           94\n",
            "----------------------------------------------------------------------\n",
            "metric: AC\n",
            "train: 11 test: 2\n",
            "accuracy: 0.9405365441487115\n",
            "          Predicted L  Predicted H\n",
            "Actual L          934         1026\n",
            "Actual H          663        25781\n",
            "----------------------------------------------------------------------\n",
            "metric: PR\n",
            "train: 11 test: 2\n",
            "accuracy: 0.7965427404590902\n",
            "          Predicted N  Predicted L  Predicted H\n",
            "Actual N          484          524          776\n",
            "Actual L          159         4214         3106\n",
            "Actual H           83         1131        17927\n",
            "----------------------------------------------------------------------\n",
            "metric: UI\n",
            "train: 11 test: 2\n",
            "accuracy: 0.8729404309252218\n",
            "          Predicted N  Predicted R\n",
            "Actual N        16809         1041\n",
            "Actual R         2568         7986\n",
            "----------------------------------------------------------------------\n",
            "metric: S\n",
            "train: 11 test: 2\n",
            "accuracy: 0.9620475989297282\n",
            "          Predicted U  Predicted C\n",
            "Actual U         3984          832\n",
            "Actual C          246        23342\n",
            "----------------------------------------------------------------------\n",
            "metric: C\n",
            "train: 11 test: 2\n",
            "accuracy: 0.8205534431770173\n",
            "          Predicted N  Predicted L  Predicted H\n",
            "Actual N        15007          681          942\n",
            "Actual L         1043         4157          288\n",
            "Actual H         2008          135         4143\n",
            "----------------------------------------------------------------------\n",
            "metric: I\n",
            "train: 11 test: 2\n",
            "accuracy: 0.838895930150683\n",
            "          Predicted N  Predicted L  Predicted H\n",
            "Actual N        12987          468         1348\n",
            "Actual L          721         3989          239\n",
            "Actual H         1666          134         6852\n",
            "----------------------------------------------------------------------\n",
            "metric: A\n",
            "train: 11 test: 2\n"
          ]
        }
      ]
    }
  ]
}